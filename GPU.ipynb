{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Clone the transformers repository\n",
    "!git clone https://github.com/huggingface/transformers\n",
    "\n",
    "# Install the transformers library\n",
    "os.chdir('transformers')\n",
    "!pip install .\n",
    "\n",
    "# Navigate to the language modeling example directory and install required packages\n",
    "os.chdir('examples/pytorch/language-modeling')\n",
    "!pip install -r requirements.txt\n",
    "\n",
    "# Define default argument values\n",
    "model_name_or_path = '/path/to/model'\n",
    "train_file = '/path/to/train.json'\n",
    "validation_file = '/path/to/val.json'\n",
    "output_dir = '/path/to/output'\n",
    "per_device_train_batch_size = 1\n",
    "per_device_eval_batch_size = 1\n",
    "num_train_epochs = 2\n",
    "logging_steps = 100\n",
    "save_steps = 5000\n",
    "gradient_accumulation_steps = 64\n",
    "learning_rate = 5e-5\n",
    "warmup_steps = 500\n",
    "adam_beta1 = 0.9\n",
    "adam_beta2 = 0.98\n",
    "weight_decay = 0.01\n",
    "block_size = 2048\n",
    "\n",
    "# Define text boxes for entering argument values\n",
    "model_name_or_path_textbox = widgets.Text(description='Model name or path:', value=model_name_or_path)\n",
    "train_file_textbox = widgets.Text(description='Train file:', value=train_file)\n",
    "validation_file_textbox = widgets.Text(description='Validation file:', value=validation_file)\n",
    "output_dir_textbox = widgets.Text(description='Output directory:', value=output_dir)\n",
    "per_device_train_batch_size_textbox = widgets.IntText(description='Per-device train batch size:', value=per_device_train_batch_size)\n",
    "per_device_eval_batch_size_textbox = widgets.IntText(description='Per-device eval batch size:', value=per_device_eval_batch_size)\n",
    "num_train_epochs_textbox = widgets.IntText(description='Num train epochs:', value=num_train_epochs)\n",
    "logging_steps_textbox = widgets.IntText(description='Logging steps:', value=logging_steps)\n",
    "save_steps_textbox = widgets.IntText(description='Save steps:', value=save_steps)\n",
    "gradient_accumulation_steps_textbox = widgets.IntText(description='Gradient accumulation steps:', value=gradient_accumulation_steps)\n",
    "learning_rate_textbox = widgets.FloatText(description='Learning rate:', value=learning_rate)\n",
    "warmup_steps_textbox = widgets.IntText(description='Warmup steps:', value=warmup_steps)\n",
    "adam_beta1_textbox = widgets.FloatText(description='Adam beta1:', value=adam_beta1)\n",
    "adam_beta2_textbox = widgets.FloatText(description='Adam beta2:', value=adam_beta2)\n",
    "weight_decay_textbox = widgets.FloatText(description='Weight decay:', value=weight_decay)\n",
    "block_size_textbox = widgets.IntText(description='Block size:', value=block_size)\n",
    "\n",
    "# Create the sidebar\n",
    "sidebar = widgets.VBox([model_name_or_path_textbox,\n",
    "                        train_file_textbox,\n",
    "                        validation_file_textbox,\n",
    "                        output_dir_textbox,\n",
    "                        per_device_train_batch_size_textbox,\n",
    "                        per_device_eval_batch_size_textbox,\n",
    "                        num_train_epochs_textbox,\n",
    "                        logging_steps_textbox,\n",
    "                        save_steps_textbox,\n",
    "                        gradient_accumulation_steps_textbox,\n",
    "                        learning_rate_textbox,\n",
    "                        warmup_steps_textbox,\n",
    "                        adam_beta1_textbox,\n",
    "                        adam_beta2_textbox,\n",
    "                        weight_decay_textbox,\n",
    "                        block_size_textbox])\n",
    "\n",
    "# Define a function to run the command with the entered argument values\n",
    "def run_command(b):\n",
    "    command = 'python run_clm.py'\n",
    "    command += f' --model_name_or_path {model_name_or_path_textbox.value}'\n",
    "    command += f' --train_file {train_file_textbox.value}'\n",
    "    command += f' --validation_file {validation_file_textbox.value}'\n",
    "    command += ' --do_train --do_eval'\n",
    "    command += f' --output_dir {output_dir_textbox.value}'\n",
    "    command += ' --overwrite_output_dir'\n",
    "    command += f' --per_device_train_batch_size {per_device_train_batch_size_textbox.value}'\n",
    "    command += f' --per_device_eval_batch_size {per_device_eval_batch_size_textbox.value}'\n",
    "    command += f' --num_train_epochs {num_train_epochs_textbox.value}'\n",
    "    command += f' --logging_steps {logging_steps_textbox.value}'\n",
    "    command += f' --save_steps {save_steps_textbox.value}'\n",
    "    command += f' --gradient_accumulation_steps {gradient_accumulation_steps_textbox.value}'\n",
    "    command += f' --learning_rate {learning_rate_textbox.value}'\n",
    "    command += f' --warmup_steps {warmup_steps_textbox.value}'\n",
    "    command += f' --adam_beta1 {adam_beta1_textbox.value}'\n",
    "    command += f' --adam_beta2 {adam_beta2_textbox.value}'\n",
    "    command += f' --weight_decay {weight_decay_textbox.value}'\n",
    "    command += f' --block_size {block_size_textbox.value}'\n",
    "    \n",
    "    !{command}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
